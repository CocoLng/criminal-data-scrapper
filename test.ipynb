{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Lecture des fichiers...\n",
      "INFO:__main__:Calcul des similarités...\n",
      "INFO:__main__:Création du mapping...\n",
      "INFO:__main__:Validation du mapping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résultats du mapping:\n",
      "\n",
      "Catégorie Excel: 100\n",
      "Catégorie CSV correspondante: Homicides\n",
      "Score de similarité: 1.00\n",
      "Confiance: Moyenne\n",
      "Différence relative: 27.57%\n",
      "\n",
      "Catégorie Excel: 36\n",
      "Catégorie CSV correspondante: Cambriolages de logement\n",
      "Score de similarité: 1.00\n",
      "Confiance: Haute\n",
      "Différence relative: 16.29%\n",
      "\n",
      "Catégorie Excel: 84\n",
      "Catégorie CSV correspondante: Vols avec armes\n",
      "Score de similarité: 1.00\n",
      "Confiance: Haute\n",
      "Différence relative: 0.26%\n",
      "\n",
      "Catégorie Excel: 67\n",
      "Catégorie CSV correspondante: Vols violents sans arme\n",
      "Score de similarité: 1.00\n",
      "Confiance: Haute\n",
      "Différence relative: 16.42%\n",
      "\n",
      "Catégorie Excel: 40\n",
      "Catégorie CSV correspondante: Trafic de stupéfiants\n",
      "Score de similarité: 1.00\n",
      "Confiance: Haute\n",
      "Différence relative: 11.01%\n",
      "\n",
      "Catégorie Excel: 34\n",
      "Catégorie CSV correspondante: Vols d'accessoires sur véhicules\n",
      "Score de similarité: 1.00\n",
      "Confiance: Haute\n",
      "Différence relative: 7.70%\n",
      "\n",
      "Catégorie Excel: 42\n",
      "Catégorie CSV correspondante: Vols dans les véhicules\n",
      "Score de similarité: 1.00\n",
      "Confiance: Haute\n",
      "Différence relative: 17.68%\n",
      "\n",
      "Catégorie Excel: 11\n",
      "Catégorie CSV correspondante: Vols de véhicules\n",
      "Score de similarité: 1.00\n",
      "Confiance: Haute\n",
      "Différence relative: 10.10%\n",
      "\n",
      "Catégorie Excel: 66\n",
      "Catégorie CSV correspondante: Violences sexuelles\n",
      "Score de similarité: 1.00\n",
      "Confiance: Haute\n",
      "Différence relative: 18.23%\n",
      "\n",
      "Catégorie Excel: 106\n",
      "Catégorie CSV correspondante: Autres coups et blessures volontaires\n",
      "Score de similarité: 1.00\n",
      "Confiance: Moyenne\n",
      "Différence relative: 20.16%\n",
      "\n",
      "Catégorie Excel: 26\n",
      "Catégorie CSV correspondante: Coups et blessures volontaires intrafamiliaux\n",
      "Score de similarité: 1.00\n",
      "Confiance: Haute\n",
      "Différence relative: 19.23%\n",
      "\n",
      "Catégorie Excel: 6\n",
      "Catégorie CSV correspondante: Coups et blessures volontaires\n",
      "Score de similarité: 0.99\n",
      "Confiance: Haute\n",
      "Différence relative: 11.10%\n",
      "\n",
      "Catégorie Excel: 41\n",
      "Catégorie CSV correspondante: Usage de stupéfiants\n",
      "Score de similarité: 0.99\n",
      "Confiance: Haute\n",
      "Différence relative: 5.51%\n",
      "\n",
      "Catégorie Excel: 90\n",
      "Catégorie CSV correspondante: Escroqueries\n",
      "Score de similarité: 0.97\n",
      "Confiance: Haute\n",
      "Différence relative: 10.24%\n",
      "\n",
      "Catégorie Excel: 56\n",
      "Catégorie CSV correspondante: Destructions et dégradations volontaires\n",
      "Score de similarité: 0.87\n",
      "Confiance: Basse\n",
      "Différence relative: 65.41%\n",
      "\n",
      "Catégorie Excel: 31\n",
      "Catégorie CSV correspondante: Vols sans violence contre des personnes\n",
      "Score de similarité: 0.84\n",
      "Confiance: Basse\n",
      "Différence relative: 78.16%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from difflib import SequenceMatcher\n",
    "import logging\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class CrimeCategoryMapper:\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        \n",
    "    def read_excel_data(self, excel_file: str) -> pd.DataFrame:\n",
    "        \"\"\"Lit et transforme les données Excel mensuelles en données annuelles.\"\"\"\n",
    "        try:\n",
    "            df = pd.read_excel(excel_file)\n",
    "            \n",
    "            # Création d'un DataFrame pour les données annuelles\n",
    "            yearly_data = []\n",
    "            \n",
    "            # Pour chaque année 2020-2021 (période de validation)\n",
    "            for year in [2020, 2021]:\n",
    "                # Sélectionner les colonnes de l'année\n",
    "                year_cols = [col for col in df.columns if f\"_{year}_\" in col]\n",
    "                \n",
    "                # Somme des valeurs mensuelles\n",
    "                yearly_sum = df[year_cols].sum(axis=1)\n",
    "                \n",
    "                for idx, sum_value in yearly_sum.items():\n",
    "                    yearly_data.append({\n",
    "                        'annee': year,\n",
    "                        'categorie_excel': idx,\n",
    "                        'nombre_faits': sum_value\n",
    "                    })\n",
    "            \n",
    "            return pd.DataFrame(yearly_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erreur lors de la lecture du fichier Excel: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def read_csv_data(self, csv_file: str) -> pd.DataFrame:\n",
    "        \"\"\"Lit et prépare les données CSV.\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file, sep=';', encoding='utf-8')\n",
    "            \n",
    "            # Convertir l'année en format complet\n",
    "            df['annee'] = df['annee'].astype(str).apply(lambda x: 2000 + int(x) if len(x) == 2 else int(x))\n",
    "            \n",
    "            # Filtrer pour 2020-2021\n",
    "            df = df[df['annee'].isin([2020, 2021])]\n",
    "            \n",
    "            # Convertir les valeurs numériques\n",
    "            df['faits'] = pd.to_numeric(df['faits'], errors='coerce')\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erreur lors de la lecture du fichier CSV: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def aggregate_csv_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Agrège les données CSV par année et catégorie.\"\"\"\n",
    "        return df.groupby(['annee', 'classe'])['faits'].sum().reset_index()\n",
    "\n",
    "    def calculate_similarity_scores(self, excel_data: pd.DataFrame, csv_data: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Calcule les scores de similarité entre les catégories basés sur les patterns de données.\"\"\"\n",
    "        similarity_scores = {}\n",
    "        \n",
    "        # Pivot des données pour avoir le même format\n",
    "        excel_pivot = excel_data.pivot(index='categorie_excel', columns='annee', values='nombre_faits')\n",
    "        csv_pivot = csv_data.pivot(index='classe', columns='annee', values='faits')\n",
    "        \n",
    "        # Normalisation des données\n",
    "        excel_normalized = excel_pivot.div(excel_pivot.sum())\n",
    "        csv_normalized = csv_pivot.div(csv_pivot.sum())\n",
    "        \n",
    "        for excel_cat in excel_normalized.index:\n",
    "            similarity_scores[excel_cat] = {}\n",
    "            excel_pattern = excel_normalized.loc[excel_cat].values\n",
    "            \n",
    "            for csv_cat in csv_normalized.index:\n",
    "                csv_pattern = csv_normalized.loc[csv_cat].values\n",
    "                \n",
    "                # Calcul de la différence relative\n",
    "                similarity = 1 - np.mean(np.abs(excel_pattern - csv_pattern))\n",
    "                similarity_scores[excel_cat][csv_cat] = similarity\n",
    "                \n",
    "        return similarity_scores\n",
    "\n",
    "    def create_mapping(self, similarity_scores: Dict) -> Dict:\n",
    "        \"\"\"Crée le mapping final basé sur les meilleurs scores de similarité.\"\"\"\n",
    "        mapping = {}\n",
    "        used_csv_categories = set()\n",
    "        \n",
    "        # Trier les correspondances par score\n",
    "        sorted_pairs = []\n",
    "        for excel_cat, scores in similarity_scores.items():\n",
    "            for csv_cat, score in scores.items():\n",
    "                sorted_pairs.append((excel_cat, csv_cat, score))\n",
    "                \n",
    "        sorted_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # Assigner les meilleures correspondances\n",
    "        for excel_cat, csv_cat, score in sorted_pairs:\n",
    "            if excel_cat not in mapping and csv_cat not in used_csv_categories:\n",
    "                mapping[excel_cat] = {\n",
    "                    'categorie_csv': csv_cat,\n",
    "                    'score_similarite': score\n",
    "                }\n",
    "                used_csv_categories.add(csv_cat)\n",
    "                \n",
    "        return mapping\n",
    "\n",
    "    def validate_mapping(self, mapping: Dict, excel_data: pd.DataFrame, csv_data: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Valide le mapping en comparant les données.\"\"\"\n",
    "        validation_results = {}\n",
    "        \n",
    "        for excel_cat, map_info in mapping.items():\n",
    "            csv_cat = map_info['categorie_csv']\n",
    "            \n",
    "            # Extraire les données pour chaque catégorie\n",
    "            excel_values = excel_data[excel_data['categorie_excel'] == excel_cat]\n",
    "            csv_values = csv_data[csv_data['classe'] == csv_cat]\n",
    "            \n",
    "            if not excel_values.empty and not csv_values.empty:\n",
    "                # Calculer la différence relative moyenne\n",
    "                excel_sum = excel_values['nombre_faits'].sum()\n",
    "                csv_sum = csv_values['faits'].sum()\n",
    "                \n",
    "                if excel_sum > 0 and csv_sum > 0:\n",
    "                    diff_ratio = abs(excel_sum - csv_sum) / max(excel_sum, csv_sum)\n",
    "                    validation_results[excel_cat] = {\n",
    "                        'categorie_csv': csv_cat,\n",
    "                        'difference_relative': diff_ratio,\n",
    "                        'confiance': 'Haute' if diff_ratio < 0.2 else 'Moyenne' if diff_ratio < 0.5 else 'Basse'\n",
    "                    }\n",
    "                    \n",
    "        return validation_results\n",
    "\n",
    "    def process_mapping(self, excel_file: str, csv_file: str) -> Dict:\n",
    "        \"\"\"Fonction principale pour créer le mapping.\"\"\"\n",
    "        try:\n",
    "            # 1. Lecture des données\n",
    "            self.logger.info(\"Lecture des fichiers...\")\n",
    "            excel_data = self.read_excel_data(excel_file)\n",
    "            csv_data = self.read_csv_data(csv_file)\n",
    "            \n",
    "            # 2. Agrégation des données CSV\n",
    "            csv_aggregated = self.aggregate_csv_data(csv_data)\n",
    "            \n",
    "            # 3. Calcul des scores de similarité\n",
    "            self.logger.info(\"Calcul des similarités...\")\n",
    "            similarity_scores = self.calculate_similarity_scores(excel_data, csv_aggregated)\n",
    "            \n",
    "            # 4. Création du mapping\n",
    "            self.logger.info(\"Création du mapping...\")\n",
    "            mapping = self.create_mapping(similarity_scores)\n",
    "            \n",
    "            # 5. Validation du mapping\n",
    "            self.logger.info(\"Validation du mapping...\")\n",
    "            validation_results = self.validate_mapping(mapping, excel_data, csv_aggregated)\n",
    "            \n",
    "            # 6. Sauvegarder les résultats\n",
    "            results = {\n",
    "                'mapping': mapping,\n",
    "                'validation': validation_results,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'metadata': {\n",
    "                    'periode_validation': '2020-2021',\n",
    "                    'nombre_categories_mappees': len(mapping)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Sauvegarder en JSON\n",
    "            with open('category_mapping_results.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erreur lors du processus de mapping: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fonction principale\"\"\"\n",
    "    mapper = CrimeCategoryMapper()\n",
    "    \n",
    "    # Exemple d'utilisation\n",
    "    try:\n",
    "        results = mapper.process_mapping(\n",
    "            excel_file=\"Chiffres crimes et délits depuis janvier 1996 - 2022.xlsx\",\n",
    "            csv_file=\"donnee-dep-data.gouv-2016-2024.csv\"\n",
    "        )\n",
    "        \n",
    "        print(\"\\nRésultats du mapping:\")\n",
    "        for excel_cat, info in results['mapping'].items():\n",
    "            validation = results['validation'].get(excel_cat, {})\n",
    "            print(f\"\\nCatégorie Excel: {excel_cat}\")\n",
    "            print(f\"Catégorie CSV correspondante: {info['categorie_csv']}\")\n",
    "            print(f\"Score de similarité: {info['score_similarite']:.2f}\")\n",
    "            if validation:\n",
    "                print(f\"Confiance: {validation['confiance']}\")\n",
    "                print(f\"Différence relative: {validation['difference_relative']:.2%}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'exécution: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Lecture des fichiers...\n",
      "ERROR:__main__:Erreur lors de la lecture du fichier Excel: [Errno 2] No such file or directory: 'Chiffres crimes et délits depuis janvier 1996  2022.xlsx'\n",
      "ERROR:__main__:Erreur lors de la fusion: [Errno 2] No such file or directory: 'Chiffres crimes et délits depuis janvier 1996  2022.xlsx'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors de l'exécution: [Errno 2] No such file or directory: 'Chiffres crimes et délits depuis janvier 1996  2022.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "class CrimeDataMerger:\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        \n",
    "        # Mapping département -> région (à compléter selon vos besoins)\n",
    "        self.dept_region_mapping = {\n",
    "            '01': '84', '02': '32', '03': '84', '04': '93', '05': '93',\n",
    "            '06': '93', '07': '84', '08': '44', '09': '76', '10': '44'\n",
    "            # ... Ajouter tous les mappings nécessaires\n",
    "        }\n",
    "        \n",
    "        self.category_mapping = {\n",
    "            '1': 'Homicides',  # Règlements de compte entre malfaiteurs\n",
    "            '2': 'Homicides'   # Homicides pour voler et à l'occasion de vols\n",
    "            # Ajouter les autres catégories selon le mapping\n",
    "        }\n",
    "\n",
    "    def get_demographic_data(self, dept: str, year: str) -> Tuple[str, str, str]:\n",
    "        \"\"\"\n",
    "        Retourne les données démographiques (POP, LOG, tauxpourmille) pour un département et une année\n",
    "        Pour l'instant, retourne des valeurs vides car ces données ne sont pas disponibles dans l'Excel\n",
    "        \"\"\"\n",
    "        return ('', '', '')\n",
    "\n",
    "    def read_csv_data(self, csv_file: str) -> pd.DataFrame:\n",
    "        \"\"\"Lit les données CSV avec le format exact\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file, sep=';', encoding='utf-8', dtype={\n",
    "                'classe': str,\n",
    "                'annee': str,\n",
    "                'Code.département': str,\n",
    "                'Code.région': str,\n",
    "                'unité.de.compte': str,\n",
    "                'millPOP': str,\n",
    "                'millLOG': str,\n",
    "                'faits': str,\n",
    "                'POP': str,\n",
    "                'LOG': str,\n",
    "                'tauxpourmille': str\n",
    "            })\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erreur lors de la lecture du fichier CSV: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def read_excel_data(self, excel_file: str) -> pd.DataFrame:\n",
    "        \"\"\"Lit et transforme les données Excel au format exact du CSV\"\"\"\n",
    "        try:\n",
    "            df = pd.read_excel(excel_file)\n",
    "            transformed_data = []\n",
    "\n",
    "            # Pour chaque année de 1996 à 2015\n",
    "            for year in range(1996, 2016):\n",
    "                year_suffix = str(year)[-2:]\n",
    "                year_cols = [col for col in df.columns if f\"_{year}_\" in col]\n",
    "                \n",
    "                if year_cols:\n",
    "                    # Pour chaque catégorie\n",
    "                    for idx in df.index:\n",
    "                        if str(idx) in self.category_mapping:\n",
    "                            # Somme des valeurs mensuelles\n",
    "                            yearly_sum = df.loc[idx, year_cols].sum()\n",
    "                            \n",
    "                            # Pour chaque département\n",
    "                            for dept in self.dept_region_mapping:\n",
    "                                transformed_data.append({\n",
    "                                    'classe': self.category_mapping[str(idx)],\n",
    "                                    'annee': year_suffix,\n",
    "                                    'Code.département': dept,\n",
    "                                    'Code.région': self.dept_region_mapping[dept],\n",
    "                                    'unité.de.compte': 'victime' if self.category_mapping[str(idx)] == 'Homicides' else 'faits',\n",
    "                                    'millPOP': year_suffix,\n",
    "                                    'millLOG': year_suffix,\n",
    "                                    'faits': str(int(yearly_sum / len(self.dept_region_mapping))),\n",
    "                                    'POP': '',\n",
    "                                    'LOG': '',\n",
    "                                    'tauxpourmille': ''\n",
    "                                })\n",
    "\n",
    "            return pd.DataFrame(transformed_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erreur lors de la lecture du fichier Excel: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def merge_data(self, excel_data: pd.DataFrame, csv_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Fusionne les données en respectant le format exact\"\"\"\n",
    "        try:\n",
    "            # Définir l'ordre exact des colonnes\n",
    "            columns = ['classe', 'annee', 'Code.département', 'Code.région', \n",
    "                      'unité.de.compte', 'millPOP', 'millLOG', 'faits', \n",
    "                      'POP', 'LOG', 'tauxpourmille']\n",
    "\n",
    "            # S'assurer que les deux DataFrames ont le même format\n",
    "            excel_data = excel_data.reindex(columns=columns)\n",
    "            csv_data = csv_data.reindex(columns=columns)\n",
    "\n",
    "            # Fusionner les données\n",
    "            merged_data = pd.concat([\n",
    "                excel_data[excel_data['annee'].astype(int) < 16],  # Données Excel avant 2016\n",
    "                csv_data[csv_data['annee'].astype(int) >= 16]      # Données CSV à partir de 2016\n",
    "            ], ignore_index=True)\n",
    "\n",
    "            # Trier les données\n",
    "            merged_data = merged_data.sort_values(['annee', 'classe', 'Code.département'])\n",
    "\n",
    "            return merged_data\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erreur lors de la fusion: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def process_merge(self, excel_file: str, csv_file: str) -> pd.DataFrame:\n",
    "        \"\"\"Fonction principale pour la fusion des données\"\"\"\n",
    "        try:\n",
    "            # 1. Lecture des fichiers\n",
    "            self.logger.info(\"Lecture des fichiers...\")\n",
    "            excel_data = self.read_excel_data(excel_file)\n",
    "            csv_data = self.read_csv_data(csv_file)\n",
    "\n",
    "            # 2. Fusion des données\n",
    "            self.logger.info(\"Fusion des données...\")\n",
    "            merged_data = self.merge_data(excel_data, csv_data)\n",
    "\n",
    "            # 3. Sauvegarde du résultat\n",
    "            output_file = f'crimes_delits_fusion_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "            merged_data.to_csv(output_file, sep=';', index=False, encoding='utf-8')\n",
    "            \n",
    "            # 4. Affichage des statistiques\n",
    "            print(\"\\nExemple de données fusionnées (5 premières lignes):\")\n",
    "            print(merged_data.head().to_string())\n",
    "            \n",
    "            return merged_data\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erreur lors de la fusion: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    merger = CrimeDataMerger()\n",
    "    try:\n",
    "        merged_data = merger.process_merge(\n",
    "            excel_file=\"Chiffres crimes et délits depuis janvier 1996  2022.xlsx\",\n",
    "            csv_file=\"donneedepdata.gouv20162024.csv\"\n",
    "        )\n",
    "        \n",
    "        print(\"\\nVérification du format:\")\n",
    "        print(f\"Nombre total de lignes: {len(merged_data)}\")\n",
    "        print(f\"Colonnes présentes: {merged_data.columns.tolist()}\")\n",
    "        print(f\"Types de données: \\n{merged_data.dtypes}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'exécution: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
